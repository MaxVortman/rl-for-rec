{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"./prepared_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_tr = pd.read_csv(os.path.join(DATA_DIR, 'validation_tr.csv'))\n",
    "val_data_te = pd.read_csv(os.path.join(DATA_DIR, 'validation_te.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_tr = pd.read_csv(os.path.join(DATA_DIR, 'test_tr.csv'))\n",
    "test_data_te = pd.read_csv(os.path.join(DATA_DIR, 'test_te.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item = pd.concat([train_data, val_data_tr, test_data_tr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the user_item_matrix will look like this\n",
    "# |        | item 1 | ... | item m |\n",
    "# |--------|--------|-----|--------|\n",
    "# | user 1 | 3      | 0   | 0      |\n",
    "# | ...    | 0      | 4   | 5      |\n",
    "# | user n | 2      | 0   | 0      |\n",
    "\n",
    "users, items = user_item['uid'], user_item['sid']\n",
    "unique_u, unique_i = pd.unique(users), pd.unique(items)\n",
    "user_item_matrix = csr_matrix((np.ones_like(users), (users, items)), shape=(unique_u.shape[0], unique_i.shape[0]), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_latent_factors, epsilon=1e-9):\n",
    "    # generate item lantent features\n",
    "    item_svd = TruncatedSVD(n_components = n_latent_factors)\n",
    "    item_features = item_svd.fit_transform(user_item_matrix.transpose()) + epsilon\n",
    "\n",
    "    # generate user latent features\n",
    "    user_svd = TruncatedSVD(n_components = n_latent_factors)\n",
    "    user_features = user_svd.fit_transform(user_item_matrix) + epsilon\n",
    "\n",
    "    return user_features, item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(user_features, item_features, users, user_viewed_items, k=100):\n",
    "    rating_u = np.mean(user_item_matrix) + np.dot(user_features[users], item_features.T)\n",
    "    for i in range(users.shape[0]):\n",
    "        rating_u[i][user_viewed_items[users[i]]] = 0\n",
    "    top_k_i = np.argsort(-rating_u, axis=1)[:,:k]\n",
    "    return top_k_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg(true, pred, k=100):\n",
    "        '''\n",
    "        normalized discounted cumulative gain@k for binary relevance\n",
    "        ASSUMPTIONS: all the 0's in true indicate 0 relevance\n",
    "        '''\n",
    "        # build the discount template\n",
    "        tp = 1. / np.log2(np.arange(2, k + 2))\n",
    "        DCG = (np.take_along_axis(true, pred, axis=1) * tp).sum(axis=1)\n",
    "        IDCG = np.array([(tp[:min(int(n), k)]).sum()\n",
    "                             for n in (true != 0).sum(axis=1)])\n",
    "        return DCG / IDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_val_users = pd.unique(val_data_te['uid'])\n",
    "val_user_items_to_remove = val_data_tr.groupby('uid')['sid'].apply(list)\n",
    "val_users, val_items = val_data_te['uid'], val_data_te['sid']\n",
    "val_user_item_matrix = csr_matrix((np.ones_like(val_users), (val_users, val_items)), shape=(unique_u.shape[0], unique_i.shape[0]), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@100 for 8 latent factors is 0.10507154822498767\n",
      "NDCG@100 for 16 latent factors is 0.10201432434861857\n",
      "NDCG@100 for 32 latent factors is 0.10406248834038938\n",
      "NDCG@100 for 64 latent factors is 0.1052579980649808\n",
      "NDCG@100 for 128 latent factors is 0.10436894471836142\n",
      "NDCG@100 for 256 latent factors is 0.10620641444878592\n",
      "Best NDCG@100 is 0.10620641444878592 for 256 features\n"
     ]
    }
   ],
   "source": [
    "best_feats = (None, None)\n",
    "best_score = 0\n",
    "best_n = 0\n",
    "for n in [8, 16, 32, 64, 128, 256]:\n",
    "    user_feats, item_feats = train(n)\n",
    "    val_pred = predict(user_feats, item_feats, unique_val_users, val_user_items_to_remove)\n",
    "    ndcg_score = ndcg(val_user_item_matrix[unique_val_users].toarray(), val_pred).mean()\n",
    "    print(f\"NDCG@100 for {n} latent factors is {ndcg_score}\")\n",
    "    if ndcg_score > best_score:\n",
    "        best_score = ndcg_score\n",
    "        best_feats = (user_feats, item_feats)\n",
    "        best_n = n\n",
    "print(f\"Best NDCG@100 is {best_score} for {best_n} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_test_users = pd.unique(test_data_te['uid'])\n",
    "test_user_items_to_remove = test_data_tr.groupby('uid')['sid'].apply(list)\n",
    "test_users, test_items = test_data_te['uid'], test_data_te['sid']\n",
    "test_user_item_matrix = csr_matrix((np.ones_like(test_users), (test_users, test_items)), shape=(unique_u.shape[0], unique_i.shape[0]), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10664642803962227\n"
     ]
    }
   ],
   "source": [
    "test_pred = predict(*best_feats, unique_test_users, test_user_items_to_remove)\n",
    "ndcg_score = ndcg(test_user_item_matrix[unique_test_users].toarray(), test_pred).mean()\n",
    "print(ndcg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "21c9aa5199837a8593138ca3afe3bdf17b59ecbe9a7669c785feee9e65fa98e9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
